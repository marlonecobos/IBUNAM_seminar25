---
title: "Ecological Niche Modeling with kuenm2"
author: ""
date: "`r Sys.Date()`"
output: html_document
---

# Install and Load Packages

```{r}
# Install package
#remotes::install_github("marlonecobos/kuenm2")

# Load packages
library(kuenm2)
library(terra)
```

# Import Data
As an example, let's use the occurrence data provided in the package. It includes 51 occurrence records of the plant species *Myrcia hatschbachii*, derived from [Trindade & Marques (2024)](https://doi.org/10.1111/ddi.13931).

```{r}
# Dataframe with occurrences (longitude and latitude)
data(occ_data, package = "kuenm2") # Data example
head(occ_data)
```
Now, let's visualize the occurrences:
```{r}
pts <- vect(occ_data, geom = c(x = "x", y = "y"), crs = "+init=epsg:4326")
plet(pts, col = "black")
```
Let's use the environmental variables provided in the package. These include four bioclimatic variables retrieved from WorldClim 2.1 and a categorical variable, soil type, retrieved from SoilGrids.

```{r}
# Raster with environmental variables
var <- terra::rast(system.file("extdata", "Current_variables.tif", package = "kuenm2")) # Data example
plot(var)
```

For now, let's use only the four bioclimatic variables:
```{r}
# Use only continuous variables
var <- var[[1:4]]
```

# Prepare Data for Model Calibration
The first step in the package workflow is preparing data for model calibration. This includes generating background points, performing k-fold partitioning, and defining parameter combinations with varying regularization multipliers, feature classes, and environmental variable sets. Optionally, environmental variables can be converted into PCA-derived variables.

It supports both algorithms glm and maxnet. Here, we will fit maxnet models.

We will use 500 random points as background. We will create a set of candidate models by considering different combinations of variables, feature types (linear, quadratic, and product), and regularization multipliers (0.1 and 1).

```{r}
# Prepare data for maxnet model
sp_swd <- prepare_data(algorithm = "maxnet", occ = occ_data,
                       species = occ_data[1, 1], x = "x", y = "y",
                       raster_variables = var,
                       min_number = 3,
                       n_background = 500, 
                       features = c("l", "lq", "lqp"),
                       reg_mult = c(0.1, 1))
sp_swd

# Calibration data (Sample with data - SWD)
head(sp_swd$calibration_data)

# Candidate models
head(sp_swd$formula_grid)

# Number of candidate models
nrow(sp_swd$formula_grid)
```

# Explore Spatial Distribution of Occurrence and Background Points
With the `explore_calibration_geo()` function, we can explore the spatial distribution of occurrence and background points:

```{r}
pbg <- explore_calibration_geo(data = sp_swd, spat_variables = var[[1]], plot = TRUE)
```

# Explore Variable Distribution for Occurrence and Background Points
With the `explore_calibration_hist()` function, we can visualize the distribution of predictor variables for occurrence (presence) and background points.

```{r}
explore_calibration_hist(data = sp_swd,
                         color_background = "#0000FF80",
                         color_presence = "#FF000080",
                         mfrow = c(2, 2), plot_median = TRUE,
                         breaks = "Scott")
```

# Calibrate maxnet Models
Now, we will fit and evaluate the candidate models using the data and grid of formulas prepared with prepare_data.

The function evaluate the model considering the follow metrics: 
- Omission rates: calculated using models trained with separate testing data subsets. Users can specify multiple omission rates to be calculated (e.g., c(5, 10)), though only one can be used as the threshold for selecting the best models.
- Partial ROC: calculated following [Peterson et al. (2008)](http://dx.doi.org/10.1016/j.ecolmodel.2007.11.008).
- Model complexity (AIC): assessed using models generated with the complete set of occurrences.
- Unimodality (optional): Assessed through the beta coefficients of quadratic terms, following [Arias-Giraldo & Cobos (2024)](https://journals.ku.edu/jbi/article/view/21742).

In this study, we will evaluate the models considering two omission rates (5% and 10%), with model selection based on the 10% omission rate.
```{r}
m <- calibration(data = sp_swd, # prepare_data output
                 omission_rate = c(5, 10), # values (in %) used to calculate the omission rate.
                 omrat_threshold = 10, #Omission rate used to select the best models
                 parallel = TRUE, #To run candidate models in parallel
                 ncores = 4, #Number of cores for parallel processing
                 test_concave = TRUE, #Whether to test and remove concave curves
                 progress_bar = FALSE) #Whether to show a progress bar
m

# See results for all candidate models
head(m$calibration_results$Summary)

# See results for selected models
head(m$selected_models)
```

# Select Best Performing Models
Although the selection procedure is conducted internally during the calibration process, we can re-select models considering other omission rates (since these were calculated during calibration) and model complexity (delta AIC).

For example, let's re-select models from the calibration results, this time considering an omission rate of 5% and a delta AIC of 10.

```{r}
m_10 <- sel_best_models(calibration_results = m, #calibration output
                       algorithm = "maxnet",
                       omrat_threshold = 5, # New omission rate
                       delta_aic = 10) # New Delta AIC

# Compare selected models
m$selected_models
m_10$selected_models
```

# Fit Selected Models
After calibrating and selecting the best-performing models, we can fit the final models, which will include the consensus (mean and median) if more than one model has been selected.

Here, we will fit the final

```{r}
fm <- fit_selected(calibration_results = m, #calibration output
                   n_replicates = 4, #Number of replicates 
                   rep_type = "kfold", #Replicate type
                   progress_bar = FALSE)
fm
```
The function also calculates the thresholds based on the omission rate used for selecting the best models

```{r}
# See Thresholds
fm$thresholds
```

# Predict Models for a Single Scenario
After fitting the final models, we can predict the results. To predict the results for a single environmental scenario, we use the predict_selected() function

```{r}
p <- predict_selected(models = fm, #fit_selected output
                      raster_variables = var, # SpatRaster of variables for predicting
                      consensus_per_model = TRUE, #compute consensus for each model across its replicates
                      consensus_general = TRUE, #compute a general consensus across all models
                      consensus = c("median", "range", "mean", "stdev"),
                      clamping = FALSE,
                      var_to_clamp = NULL,
                      type = "cloglog",
                      progress_bar = FALSE)
```
The output of the function is a list of spatRaster objects containing the results for the individual selected models and the consensus:

```{r}
# Plot replicates
plot(p[[1]]$Replicates)

# Plot consensus between replicates
plot(p[[1]]$Model_consensus)

# Plot consensus between models
plot(p$General_consensus)
```

# Variable Response Curves
The response curves of the model can be visualized using the `response_curve()` function:

```{r}
par(mfrow = c(1,3))
response_curve(models = fm, variable = "bio_1")
response_curve(models = fm, variable = "bio_7")
response_curve(models = fm, variable = "bio_12")
par(mfrow = c(1,1))
```

# Two-Way interaction response plot ####
In this case, we don't have a selected model with products. Let's use an example from the package to display a 2-way interaction plot.

```{r}
# Import example of fitted_models (output of fit_selected())
data("fitted_model_glmnet", package = "kuenm2")

#Response curves (products)
resp2var(models = fitted_model_glmnet, modelID = "Model_13",
         variable1 = "bio_1", variable2 = "bio_12")
```

# Variable importance
We can use the `var_importance()` function to evaluate the relative contribution of each variable:

```{r}
imp_maxnet <- var_importance(models = fm, progress_bar = FALSE)
# Plot using enmpa package
enmpa::plot_importance(imp_maxnet)
```

# Organize Future Climate Variables
The package includes a set of functions that facilitate the projection for multiple scenarios at once, from organizing the files into the correct folders to identifying consensus across multiple GCMs.

The `organize_future_worldclim()` function imports future climate variables downloaded from WorldClim, renames the files, and organizes them into folders categorized by year, scenario (SSP) and General Circulation Model (GCM).

This function simplifies climate data preparation, making it compatible with the prepare_proj() function and ensuring that all required variables are properly structured for modeling projections

Before using the function, download and save the future climate variables from WorldClim in a single folder. Here, we will use the variables included in the package as an example.

```{r}
in_dir <- system.file("extdata", package = "kuenm2")
list.files(in_dir)
```
Let's create a folder called Future_variables to save the variables, organized by year, scenario (SSP), and General Circulation Model (GCM):

```{r}
out_dir_future <- file.path("Future_variables")
dir.create(out_dir_future)

organize_future_worldclim(input_dir = in_dir,
                          output_dir = out_dir_future,
                          name_format = "bio_",
                          variables = NULL,
                          fixed_variables = NULL,
                          mask = NULL,
                          overwrite = TRUE, 
                          progress_bar = FALSE)
```
Let's see the structure of the folders with the variables for projection:
```{r}
list.files("Future_variables", recursive = T)
```
With the variables structured, we can prepared data for model projections to multiple scenarios.

# Prepare Data for Model Projections
The `prepare_proj()` function prepares data for model projections across multiple scenarios, storing the paths to the rasters that represent each scenario.

First, however, we need to save the current variables used to fit the model in a specific folder

```{r}
out_dir_current <- "Current_raw"
dir.create(out_dir_current)
#Save variables in the Current_raw folder
writeRaster(var, file.path(out_dir_current, "Variables.tif"), overwrite = T)
```
Now, we can prepare the data for projection. We need to specify the time periods (here, 2041-2060 and 2081-2100), the emission scenarios (here, ssp126 and ssp585), and the GCMs (here, ACCESS-CM2 and MIROC6)

```{r}
pr <- prepare_proj(models = fm,
                   present_dir = out_dir_current,
                   past_dir = NULL,
                   future_dir = out_dir_future,
                   future_period = c("2041-2060", "2081-2100"),
                   future_pscen = c("ssp126", "ssp585"),
                   future_gcm = c("ACCESS-CM2", "MIROC6"),
                   write_file = FALSE,
                   filename = NULL,
                   raster_pattern = ".tif*")
pr
```

# Project selected models for multiple scenarios
Now, we can predict the selected models across the multiple scenarios specified in the prepare_proj() function. In addition to generating predictions for each replicate, the function calculates consensus measures (e.g., mean, median) across both replicates and models.
```{r}
#Create folder to save projection results
out_dir <- file.path("Projection_results/maxnet")
dir.create(out_dir, recursive = TRUE)

p <- project_selected(models = fm,
                      projection_data = pr,
                      out_dir = out_dir,
                      consensus_per_model = TRUE,
                      consensus_general = TRUE,
                      consensus = c("median", "range", "mean", "stdev"),
                      write_replicates = TRUE,
                      clamping = FALSE,
                      var_to_clamp = NULL,
                      type = "cloglog",
                      overwrite = TRUE,
                      parallel = FALSE,
                      ncores = 1,
                      parallelType = "doSNOW",
                      progress_bar = FALSE,
                      verbose = TRUE)
p
```
Let's check the files and import some results:

```{r}
#See files
list.files(out_dir, recursive = TRUE)[1:5]

#Import some projection
res_present <- rast("Projection_results/maxnet/Present/Present/General_consensus.tiff")
res_future <- rast("Projection_results/maxnet/Future/2081-2100/ssp585/MIROC6/General_consensus.tiff")
par(mfrow = c(1,2))
plot(res_present$mean, main = "Present")
plot(res_future$mean, main = "2081-2100 - SSP85 - MIROC 6")
```

# Compute Areas of Change
The interpretation of predictions for multiple scenarios and GCMs can be straightforward. With the proj_changes() function, we can calculate the level of agreement among all GCMs for each emission scenario, focusing on how and where the projected models change over time compared to the current model. The changes include loss (contraction), gain (expansion), and stability:

```{r}
changes <- proj_changes(model_projections = p,
                        reference_id = 1,
                        consensus = "mean",
                        by_gcm = TRUE,
                        by_change = TRUE,
                        general_summary = TRUE,
                        force_resample = TRUE,
                        write_results = FALSE,
                        output_dir = NULL,
                        overwrite = FALSE,
                        return_rasters = TRUE)

#See results
plot(changes$Binarized) #SpatRaster with the binarized models for each GCM
plot(changes$Results_by_gcm) #SpatRaster with the computed changes for each GCM
plot(changes$Results_by_change$`Future_2041-2060_ssp126`) #List containing the SpatRaster with each computed change for each GCM
plot(changes$Summary_changes) #SpatRaster with the general summary
```

# Prediction variance coming from distinct sources ####
With the `modvar()` function, we can calculate the variance in model predictions, distinguishing between different sources of variation, including replicates, model parameterizations, and general circulation models (GCMs)
```{r}
v <- modvar(model_projections = p,
            by_replicate = T,
            by_gcm = TRUE,
            by_model = TRUE,
            consensus = "median",
            write_files = FALSE,
            output_dir = NULL,
            return_rasters = TRUE,
            progress_bar = FALSE,
            verbose = TRUE,
            overwrite = FALSE)
#Plot some results
plot(v$Present$by_rep) #Variance coming from replicates in Present projection
plot(v$Present$by_model) #Variance coming from models in Present projection
plot(v$`Future_2041-2060_ssp126`$by_rep) #Variance coming from replicates in one of the future projections
plot(v$`Future_2041-2060_ssp126`$by_model) #Variance coming from models in one of the future projections

plot(v$`Future_2041-2060_ssp126`$by_gcm) #Variance coming from GCMs in one of the future projections
plot(v$`Future_2041-2060_ssp585`$by_gcm) #Variance coming from GCMs in one of the future projections
plot(v$`Future_2081-2100_ssp126`$by_gcm) #Variance coming from GCMs in one of the future projections
plot(v$`Future_2081-2100_ssp585`$by_gcm) #Variance coming from GCMs in one of the future projections
```

# Analyze Extrapolation Risks Using MOP Metric
To identify non-analogous conditions in the projected areas when compared to the calibration area, we can perform an analysis of extrapolation risks using the mobility-oriented parity metric (MOP):

```{r}
out_dir <- file.path("MOP_results")
dir.create(out_dir, recursive = TRUE)

kmop <- kuenm_mop(data = sp_swd,
                  subset_variables = TRUE,
                  mask = NULL,
                  fitted_models = fm,
                  projection_data = pr,
                  out_dir = out_dir,
                  type = "detailed",
                  progress_bar = FALSE,
                  overwrite = TRUE)
```
Let’s plot some results. The simple MOP shows the number of variables with non-analogous conditions across the projected scenario:
```{r}
#Import simple mop
simple_mop_files <- list.files("MOP_results/Future/",
                               recursive = TRUE, full.names = TRUE,
                               pattern = "simple")
#Remove aux files
simple_mop_files <- simple_mop_files[!grepl("aux", simple_mop_files)]
#Read rasters
simple_mop <- rast(simple_mop_files)
#Rename rasters
names(simple_mop) <- sub("\\_mopsimple.tif$", "", gsub("/", "-",
                                              sub(".*MOP_results/", "", simple_mop_files)))
#Plot
plot(simple_mop)
```

A more detailed view of the non-analogous conditions can be obtained by examining the combinations of variables that exhibit non-analogous conditions at both the low and high ends of the variable range:

```{r}
#Import detailed mop
detailed_mop_files <- list.files("MOP_results/Future/",
                               recursive = TRUE, full.names = TRUE,
                               pattern = "combined")
#Remove aux and csv files
detailed_mop_files <- detailed_mop_files[!grepl("aux|csv", detailed_mop_files)]
#Read rasters
detailed_mop <- rast(detailed_mop_files)
#Rename rasters
names(detailed_mop) <- sub("\\.tif$", "", gsub("/", "-",
                           sub(".*MOP_results/", "", detailed_mop_files)))
#Remove results with NA
na_results <- sapply(detailed_mop, function(x) !is.na(minmax(x)[1]))
detailed_mop <- detailed_mop[[na_results]]
#Plot first 8 mop results
plot(detailed_mop, cex.main= 0.5)
```

